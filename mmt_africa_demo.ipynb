{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3801a4d3-810e-4f13-a126-1ba7dcf75902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/soe/vigneshs/miniconda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional, Tuple, Union, List, Dict, Any\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict, load_metric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast, MBart50Tokenizer, MBartTokenizer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, MT5ForConditionalGeneration\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput, BaseModelOutput\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78604566-3337-431b-8a55-fd451e9a5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "_numpy_rng = np.random.default_rng(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85da7bdd-0456-4b09-8941-820c7f69936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f226c65c-20a8-4d35-b4f4-850b8aae023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to run the model on\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ceda5d-de80-4a79-9c1b-56a2327aa39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'device': device,\n",
    "    'min_seq_len': 2,\n",
    "    'max_seq_len': 128,\n",
    "    'num_beams': 4,\n",
    "    'truncation': True,\n",
    "    'checkpoint': './models/mmt_africa/checkpoint/mmt_translation.pt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "072baa57-b544-4971-8740-b46b701ae43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(args: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Load the parameters passed to `translate`\n",
    "    \"\"\"\n",
    "\n",
    "    params = {}\n",
    "    model_repo = 'google/mt5-base'\n",
    "    LANG_TOKEN_MAPPING = {\n",
    "                'ig': '<ig>',\n",
    "                'fon': '<fon>',\n",
    "                'en': '<en>',\n",
    "                'fr': '<fr>',\n",
    "                'rw':'<rw>',\n",
    "                'yo':'<yo>',\n",
    "                'xh':'<xh>',\n",
    "                'sw':'<sw>'\n",
    "            }\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "   \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_repo)\n",
    "\n",
    "\n",
    "    # Update tokenizer\n",
    "    special_tokens_dict = {'additional_special_tokens': list(LANG_TOKEN_MAPPING.values())}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    \n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    state_dict = torch.load(args['checkpoint'],map_location=args['device'])\n",
    "    \n",
    "    # print(state_dict)\n",
    "   \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "      \n",
    "    model = model.to(args['device'])\n",
    "\n",
    "    # Load the model, load the tokenizer, max and min seq len\n",
    "    params['model'] = model\n",
    "    params['device'] = args['device']\n",
    "    params['max_seq_len'] = args['max_seq_len'] if 'max_seq_len' in args else 50\n",
    "    params['min_seq_len'] = args['min_seq_len'] if 'min_seq_len' in args else 2\n",
    "    params['tokenizer'] = tokenizer\n",
    "    params['num_beams'] = args['num_beams'] if 'num_beams' in args else 4\n",
    "    params['lang_token'] = LANG_TOKEN_MAPPING\n",
    "    params['truncation'] = args['truncation'] if 'truncation' in args else True\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b45c563-56da-491f-b0c4-22d093ae8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(\n",
    "    params: dict,\n",
    "    sentence: str,\n",
    "    source_lang: str,\n",
    "    target_lang: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a sentence and its target language, this translates the sentence\n",
    "    to the given target sentence. \n",
    "    \"\"\"\n",
    "\n",
    "    def encode_input(params,text, target_lang, tokenizer, seq_len):\n",
    "  \n",
    "        target_lang_token = params['lang_token'][target_lang]\n",
    "        print(f'target_lang_token: {target_lang_token}')\n",
    "\n",
    "        # Encode\n",
    "        input_ids = tokenizer.encode(\n",
    "            text = str(target_lang_token) + str(text),\n",
    "            return_tensors = 'pt',\n",
    "            padding = 'max_length',\n",
    "            truncation =  params['truncation'] ,\n",
    "            max_length = seq_len)\n",
    "\n",
    "        return input_ids[0]\n",
    "    \n",
    "    print(f'src: {source_lang} and tgt: {target_lang}')\n",
    "    if source_lang!='' and target_lang!='':\n",
    "        inp = [sentence]    \n",
    "   \n",
    "        input_tokens = [encode_input(params,text = inp[i],target_lang = target_lang,tokenizer = params['tokenizer'],seq_len =params['max_seq_len']).unsqueeze(0).to(params['device']) for i in range(len(inp))]\n",
    "  \n",
    " \n",
    "        output = [params['model'].generate(input_ids, num_beams=params['num_beams'], num_return_sequences=1,max_length=params['max_seq_len'],min_length=params['min_seq_len']) for input_ids in input_tokens]\n",
    "        output = [params['tokenizer'].decode(out[0], skip_special_tokens=True) for out in tqdm(output)]\n",
    "  \n",
    "        return output[0]\n",
    "    \n",
    "    else:\n",
    "        return None    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb166c2-8696-4fa6-a727-6ff782761f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e9a45a5-9ccc-4aab-b407-d0ef4e76f249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = load_params(args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce96fc36-2b35-486c-81b5-fa97102776fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_text = 'My name is vignesh'\n",
    "source_text = 'How was your weekend?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f0fb99d-d7f5-4b3a-b1f9-7b39f3168145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: en and tgt: sw\n",
      "target_lang_token: <sw>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4940.29it/s]\n"
     ]
    }
   ],
   "source": [
    "output = translate(\n",
    "    params = params,\n",
    "    sentence = source_text,\n",
    "    source_lang = 'en',\n",
    "    target_lang = 'sw'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79a7ab4e-b4fa-4b21-80e7-d387997b368e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jina langu ni vignesh.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dfd40a4-3aa1-460d-9632-65a2043ba860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jinsi ilikuwa mwishoni mwa wiki yako'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4445fd07-666d-46c4-aa96-392d0af7dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_text_2 = 'Jina langu ni vignesh.'\n",
    "source_text_2 = 'Jinsi ilikuwa mwishoni mwa wiki yako'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f6d1394-50b7-4c73-a1b7-df3da82a2801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: sh and tgt: en\n",
      "target_lang_token: <en>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5497.12it/s]\n"
     ]
    }
   ],
   "source": [
    "output_2 = translate(\n",
    "    params = params,\n",
    "    sentence = source_text_2,\n",
    "    source_lang = 'sh',\n",
    "    target_lang = 'en'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64a7e99a-8903-422b-a15d-bc508af3463f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is vignesh.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84c82d87-fcd2-4ea8-a545-717db88efb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How it was that weekend'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
